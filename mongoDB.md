## mongoDB STUDY

1. 몽고디비에서 파이썬으로 데이터 끌어올 때 어떻게 하면 더 빠르게 가져올 수 있을까?
현재 ) db.plbcManifest
      - 데이터 로딩하는 데에 걸린 시간: 155.0392439365387 초
      - CSV파일로 저장하는 데에 걸린 시간: 9.610374212265015 초
      - Excel파일로 저장하는 데에 걸린 시간: 560.4967248439789 초
  
      db.plbcContainerIoResult
      - 데이터 로딩하는 데에 걸린 시간: 52.47310209274292 초
      - CSV파일로 저장하는 데에 걸린 시간: 4.91783881187439 초
      - Excel파일로 저장하는 데에 걸린 시간: 149.93564176559448 초

---
https://devs0n.tistory.com/33

[병렬로 처리]
  db.plbcManifest
      
      - 데이터 로딩하는 데에 걸린 시간: 136.75098514556885 초
      
      - CSV파일로 저장하는 데에 걸린 시간: 6.960592031478882 초
      
      - Excel파일로 저장하는 데에 걸린 시간: 612.5646040439606 초

근데 저장된 CSV 파일을 확인해보니 전체 데이터가 100만개가 아니라 87만개 정도로 추정. ( >> 데이터가 일부 들어오지 않은듯. )

시간이 빠를수록 무조건 좋다!

---

## 04/01 스크럼
[공부해볼 분야]
FastAPI : 파이썬 쪽의 API (토큰 받아서 사용하는 방식 공부해볼 것.)
'몽고디비 -> 파이썬'으로 데이터다운로드 쪽만 파이썬에서 할 수도 있기에 에이피아이를 파이썬 서버로 올릴 수도 있음.

## 04/01 회의
- 다운로드 형식을 선택할 수 있도록? >> 모든 형태가 다 가능하기는 함.
- 파일별 예상 금액을 미리 제시도 가능? >> 미리 파일을 다운로드 해놓고, 용량별로 가격 부과하여 표시하면 가능할 듯
- xml은 웹에서 주로 사용하기 때문에 잘 사용하지 않음 >> 구조 다시 잡음.
- json 형태도 생각해볼 것 (주로 제공하는 데이터 형태는 csv, excel, json)
- 맞춤데이터 >> 원하는 데이터의 형태를 custom 문의를 받아서 제공
      - join 할 때의 결측치를 고민할 필요가 없이 문의를 하기 때문에 단가를 더 높여서!
- 1안: 이상치/결측치를 제시한 뒤에 본인이 판단하도록? // 2안: 이상치/결측치를 정제한 뒤에 테이블 join 후에 제공
      - raw 데이터를 건드리는 것은 의미가 없음.
- 동일한 데이터를 정제한 후에 품질을 높여서 따로 제공하는 것도 좋은 방법
- raw 데이터들 중에서 상품값어치(인기있는 데이터)가 있는 애들만 선별해서 정제 후에 제공하면 좋을 듯
- 가치있는 데이터부터 띄어쓰기, 암호화 등의 간단한 전처리들부터 진행한 뒤에 데이터를 제공한다면?
- 한번에 전부 다 정제하는 것은 어려울 것 같음 >> 일단 되는 것부터.. 우선순위 파악할 필요가 있음
- 기본 structure에 대한 고민? 최대한 체계적이고 꼼꼼하게 구성해볼 것.
- 기존에 있는 데이터 서버 vs 데이터 판매 공간 vs 개개인의 DB
- plbc & stg?
- 서버나 디비의 개수 >> 가격도 물론 중요하지만 그보다는 생산성, 그 이유와 논리가 필요함.
- 기본 베이스 : java spring / 다운로드 데이터 정제 : python
- 멀티테넌트..?뭐?? >> 여튼 이거 보다는...
- 데이터가 10억개, 구매한 사람이 10명 ?? 그럼 데이터양이 너무 많아지기 때문에 하나의 디비에 넣어두는 게 효율적이지 않을 수 있음.

[예상되는 문제상황]

      1) 띄어쓰기 등의 정제과정은 함수를 만들어서 적용하면 되기는 함. 
      
      2) 결측치가 심하게 많은 상황.


---
## NEW TASK

1. 몽고디비에서 'plbc.ContainerIoResult', 'plbc.ContainerInOut' 두 컬렉션의 전체 데이터 가져오기
2. plbcContainerIoResult는 'copionSeq'기준, plbcContainerInOut는 '_id' 기준으로 join 진행
3. join 결과 csv파일로 저장

>>각 단계별로 시간 얼마나 걸리는지 체크할 것.

---
근데 왜 동일한 코드를 실행시킬 때마다 시간이 달라질까??

![image](https://github.com/baesunny/study_note/assets/133308712/dba1c484-1896-4c03-bab7-cb61a943b728)

![image](https://github.com/baesunny/study_note/assets/133308712/236b556d-edc2-47a7-96bc-7283df08632a)


데이터를 불러올 때 시간이 얼마나 걸리는지 확인하고 측정하는 것은 아주 중요한데, 코드를 실행할 때마다 시간이 다르게 측정되니 증말 난감하다ㅠㅠ


- 몽고디비에서 대용량의 데이터 가져올 때 가장 빠른 형태 (상위 항목부터 순서대로)
      - JSON(JavaScript 개체 표기법)
      - BSON(바이너리 JSON)
      - CSV(쉼표로 구분된 값)
